Excerpt from https://www.fsl.cs.sunysb.edu/docs/fuse/bharath-msthesis.pdf --

FUSE consists of a kernel part and a user-level daemon. The kernel part is implemented as a Linux kernel module fuse.ko which, when loaded, registers three file system types with the Virtual File System (VFS) (all visible in /proc/filesystems): 1) fuse, 2) fuseblk, and 3) fusectl. Both fuse and fuseblk are proxy types for various specific FUSE file systems that are implemented by different user-level daemons. File systems of fuse type do not require underlying block devices and are usually
stackable, in-memory, or network file systems. The fuseblk type, on the other hand, is for user-space file systems that are deployed on top of block devices, much like traditional local file systems. The Fuse and fuseblk types are similar in implementation; for a single-device file systems, however, the fuseblk provides following features:
1. Locking the block device on mount and unlocking on release;
2. Sharing the file system for multiple mounts;
3. Allowing swap files to bypass the file system in accessing the underlying device;

In addition to these features, fuseblk also provides the ability to synchronously unmount the file system: i.e, when the file system is last to be unmounted (no lazy unmounts or bind mounts remain), then the unmount call will wait until the file system acknowledges this (e.g., flushes buffers). Finally, the fusectl file system provides users with the means to control and monitor any FUSE file system behavior (e.g., for setting thresholds and counting the number of pending requests).
The fuse and fuseblk file system types are different from traditional file systems (e.g., ext4 or XFS) in that they present whole families of file systems. To differentiate between different mounted FUSE file systems, the /proc/mounts file represents every specific FUSE file system as [fuse|fuseblk].<NAME> (instead of just [fuse|fuseblk]). The <NAME> is a string identifier specified by the FUSE filesystem developer (e.g.,“dedup” if a file system deduplicates data). In addition to registering three file systems, FUSE’s kernel module also registers a /dev/fuse block device. This device serves as an interface between user-space FUSE daemons and the kernel. In general, the daemon reads FUSE requests from /dev/fuse, processes them, and then writes replies back to /dev/fuse.

FUSE’s high-level architecture --
When a user application performs some operation on a mounted FUSE file system, the VFS routes the operation to FUSE’s kernel (file system) driver. The driver allocates a FUSE request structure and puts it in a FUSE queue. At this point, the process that submitted the operation is usually put in a wait state. FUSE’s user-level daemon then picks the request from the kernel queue by reading from /dev/fuse and processes the request. Processing the request might require re-entering the kernel again: for example, in case of a stackable FUSE file system, the daemon submits operations to the underlying file system (e.g., Ext4); or in case of a block-based FUSE file system, the daemon reads or writes from the block device; and in case of a network or in-memory file system, the FUSE daemon might still need to re-enter the kernel to obtain certain system services (e.g., create a socket or get the time of day). When done with processing the request, the FUSE daemon writes the response back to /dev/fuse; FUSE’s kernel driver then marks the request as completed, and wakes up the original user process which submitted the request.
Some file system operations invoked by an application can complete without communicating with the user-level FUSE daemon. For example, reads from a previously read file, whose pages are cached in the kernel page cache, do not need to be forwarded to the FUSE driver. Caching is not limited to data: meta-data information (e.g., for stat(2)) about cached inodes or dentries (cached in Linux’s dcache) can be fully processed in kernel space without involving a FUSE daemon (depending on the mount options).
